# ğŸ¤– Robot Path Planning with Reinforcement Learning  

This project implements **robot navigation in a 2D grid world** using two key Reinforcement Learning (RL) algorithms:  
- **Q-Learning** (tabular)  
- **Deep Q-Network (DQN)**  

The goal is to train an agent (robot) to navigate through a grid with obstacles and reach the target by maximizing cumulative rewards.  

---

## ğŸš€ Features
- **Q-Learning** implementation with Îµ-greedy exploration.  
- **Deep Q-Network (DQN)** with neural network approximation.  
- Reward shaping for efficient learning.  
- Logging of training progress and visualization of results.  
- Full documentation of methods and analysis in [Final Report](docs/final-report.docx).  

---

## ğŸ“‚ Project Structure
robot-path-planning-rl/
â”œâ”€ src/
â”‚ â”œâ”€ q_learning.py # Tabular Q-Learning
â”‚ â””â”€ dqn.py # Deep Q-Network
â”œâ”€ docs/
â”‚ â””â”€ final-report.docx # Full academic report
â”œâ”€ assets/ # Screenshots / plots (optional)
â”œâ”€ requirements.txt
â””â”€ README.md

---

## âš™ï¸ Installation & Setup

1. Clone the repository:
bash
git clone https://github.com/segevis/robot-path-planning-rl.git
cd robot-path-planning-rl
Create a virtual environment (optional but recommended):
python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac: source .venv/bin/activate

Install dependencies:
pip install -r requirements.txt


â–¶ï¸ Running the Algorithms
Run Q-Learning:
python src/q_learning.py
Run DQN:
python src/dqn.py


---

## ğŸ“Š Results
- **Q-Learning**: works well on small grid environments, fast to implement and explain.  
- **DQN**: scales better to larger and more complex environments, thanks to the neural network function approximation.  
- The trade-off: Q-Learning is simple and interpretable, while DQN is more powerful but requires more compute.

## ğŸ“¸ Example Results

![Training Animation](assets/×ª××•× ×”1.gif)

![Reward Curve](assets/×ª××•× ×”3.png)

---

## ğŸ’¡ What I Learned
- Hands-on practice with Reinforcement Learning fundamentals.  
- How to implement and compare classical (tabular) vs. deep learning approaches.  
- Debugging, hyperparameter tuning, and analyzing convergence in RL.  
- Presenting results in a clear and reproducible way.  

---

## ğŸ‘¤ Author
Developed by **Segev** as part of an academic Artificial Intelligence project.


